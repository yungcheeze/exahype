/**
 * This file is part of the ExaHyPE project.
 * Copyright (c) 2016  http://exahype.eu
 * All rights reserved.
 *
 * The project has received funding from the European Union's Horizon
 * 2020 research and innovation programme under grant agreement
 * No 671698. For copyrights and licensing, please consult the webpage.
 *
 * Released under the BSD 3 Open Source License.
 * For the full license text, see LICENSE.txt
 **/

#include <cstring>

#include "tarch/la/Vector.h"
#include "tarch/multicore/Loop.h"
#include "peano/datatraversal/autotuning/Oracle.h"

#include "../../../../DGMatrices.h"
#include "../../../../GaussLegendreQuadrature.h"
#include "../../../../KernelUtils.h"

#include "SharedMemoryLabels.h"

#if DIMENSIONS == 3

namespace kernels {
namespace aderdg {
namespace generic {
namespace c {

namespace {

/*
 * For the linear kernels, we need the material parameters in the
 * space-time predictor lQi, time-averaged predictor lQhi,
 * and extrapolated predictor lQhbnd.
 * Currently we simply copy them over from the solution array.
 * 
 * !!! WARNING: ncp argument BGradQ is a dim x nVar tensor for the linear scheme 
 */
template <bool useSource, bool useNCP, typename SolverType>
void aderPicardLoopNonlinear(SolverType& solver,
    const double* luh, const double dt,
    const tarch::la::Vector<DIMENSIONS, double>& dx,
    double* lQi, double *lQi_old, double* rhs, double* rhs_0,
    double* lFi, double* gradQ, double* BGradQ) {
  constexpr int numberOfVariables  = SolverType::NumberOfVariables;
  constexpr int numberOfParameters = SolverType::NumberOfParameters;
  constexpr int numberOfData       = numberOfVariables+numberOfParameters;
  constexpr int order              = SolverType::Order;
  constexpr int basisSize          = order+1;
  constexpr int basisSize2         = basisSize * basisSize;
  constexpr int basisSize4         = basisSize2 * basisSize2;

  assertion(numberOfVariables>=0);
  assertion(numberOfParameters>=0);

  idx4 idx_luh(basisSize, basisSize, basisSize, numberOfData);
  
  idx5 idx_lQi(basisSize, basisSize, basisSize, basisSize, numberOfData);
  
  idx6 idx_lFi(basisSize, basisSize, basisSize, basisSize, DIMENSIONS + 1, numberOfVariables);

  // 1. Trivial initial guess
  auto grainSizeTrivialGuess = peano::datatraversal::autotuning::Oracle::getInstance().parallelise(basisSize,sharedmemorylabels::GenericKernelsTrivialGuessLoop);
  //for (int i = 0; i < basisSize; i++) { // i == z
  pfor(i,0,basisSize,grainSizeTrivialGuess.getGrainSize())
    for (int j = 0; j < basisSize; j++) { // j == y
      for (int k = 0; k < basisSize; k++) { // k == x
        for (int l = 0; l < basisSize; l++) { // l==t
          // Fortran: lQi(m,:,k,j,i) = luh(m,k,j,i)
          std::copy_n (luh + idx_luh(i, j, k, 0), numberOfData,
                       lQi + idx_lQi(i, j, k, l, 0));
        }
      }
    }
  endpfor
  grainSizeTrivialGuess.parallelSectionHasTerminated();

  // 2. Compute the contribution of the initial condition uh to the time update
  // ASSUMABLY: idx_rhs(t,z,y,x,nVar)
  idx5 idx_rhs(basisSize, basisSize, basisSize, basisSize, numberOfVariables);

  auto grainSizeComputeOldSolutionsImpactOnRhs = peano::datatraversal::autotuning::Oracle::getInstance().parallelise(basisSize,sharedmemorylabels::GenericKernelsComputeOldSolutionsImpactOnRhs);
  //for (int i = 0; i < basisSize; i++) {
  pfor(i,0,basisSize,grainSizeComputeOldSolutionsImpactOnRhs.getGrainSize())
    for (int j = 0; j < basisSize; j++) {
      for (int k = 0; k < basisSize; k++) {
        const double weight = kernels::gaussLegendreWeights[order][i] *
            kernels::gaussLegendreWeights[order][j] *
            kernels::gaussLegendreWeights[order][k];
        for (int l = 0; l < numberOfVariables; l++) {  // l == numberOfVariables
          for (int m = 0; m < basisSize; m++) {  // m == time
            rhs_0[idx_rhs(m, i, j, k, l)] =
                weight * kernels::F0[order][m] * luh[idx_luh(i, j, k, l)];
          }
        }
      }
    }
  endpfor
  grainSizeComputeOldSolutionsImpactOnRhs.parallelSectionHasTerminated();

  // 3. Discrete Picard iterations
  constexpr int MaxIterations = 2 * (order + 1);

  // spatial gradient of q
  // idx_gradQ(z,y,x,t,nDim,nVar)
  idx6 idx_gradQ(basisSize, basisSize, basisSize, basisSize, DIMENSIONS, numberOfVariables);

  for (int iter = 0; iter < MaxIterations; iter++) {
    // Save old space-time DOF
    std::memcpy(lQi_old, lQi, basisSize4 * numberOfData * sizeof(double));

    for (int i = 0; i < basisSize; i++) {  // time DOF
      // Compute the fluxes
      auto grainSizeFluxSourceNCPLoop = peano::datatraversal::autotuning::Oracle::getInstance().parallelise(basisSize,sharedmemorylabels::GenericKernelsFluxSourceNCPLoop);
      //for (int j = 0; j < basisSize; j++) { // z
      pfor(j,0,basisSize,grainSizeFluxSourceNCPLoop.getGrainSize())
        for (int k = 0; k < basisSize; k++) { // y
          for (int l = 0; l < basisSize; l++) { // x
            // Call PDE fluxes
            const double* Q = lQi + idx_lQi(j, k, l, i, 0);
            double* F[3];
            F[0] = lFi + idx_lFi(i, j, k, l, 0, 0);
            F[1] = lFi + idx_lFi(i, j, k, l, 1, 0);
            F[2] = lFi + idx_lFi(i, j, k, l, 2, 0);
            solver.flux(Q, F);

            // the algebraic source call moved together with ncp products
            // to the end.
          }
        }
      endpfor
      grainSizeFluxSourceNCPLoop.parallelSectionHasTerminated();

      // Copy rhs0 -> rhs
      auto grainSizeCopyRhs = peano::datatraversal::autotuning::Oracle::getInstance().parallelise(basisSize,sharedmemorylabels::GenericKernelsCopyRhs);
      //for (int j = 0; j < basisSize; j++) {
      pfor(j,0,basisSize,grainSizeCopyRhs.getGrainSize())
        for (int k = 0; k < basisSize; k++) {
          for (int l = 0; l < basisSize; l++) {
            for (int m = 0; m < numberOfVariables; m++) {
              rhs[idx_rhs(i, j, k, l, m)] = rhs_0[idx_rhs(i, j, k, l, m)];
            }
          }
        }
      endpfor
      grainSizeCopyRhs.parallelSectionHasTerminated();

      // Compute gradients only if nonconservative contributions have to be
      // computed. 
      if(useNCP) {
        std::memset(gradQ, 0, basisSize4 * DIMENSIONS * numberOfVariables * sizeof(double));
      }
      
      // Compute the "derivatives" (contributions of the stiffness matrix)
      // x direction (independent from the y and z derivatives)
      auto grainSizeComputeDerivatives = peano::datatraversal::autotuning::Oracle::getInstance().parallelise(basisSize,sharedmemorylabels::GenericKernelsComputeDerivatives);
      //for (int j = 0; j < basisSize; j++) { // z
      pfor(j,0,basisSize,grainSizeComputeDerivatives.getGrainSize())
        for (int k = 0; k < basisSize; k++) { // y
          const double weight = kernels::gaussLegendreWeights[order][i] *
              kernels::gaussLegendreWeights[order][j] *
              kernels::gaussLegendreWeights[order][k];
          const double updateSize = weight * dt / dx[0];

          // Matrix operation
          for (int l = 0; l < basisSize; l++) { // x
            for (int m = 0; m < numberOfVariables; m++) {
              for (int n = 0; n < basisSize; n++) {
                rhs[idx_rhs(i, j, k, l, m)] -= updateSize *
                    lFi[idx_lFi(i, j, k, n, 0, m)] *
                    kernels::Kxi[order][n][l];
                if(useNCP) {
                  gradQ[idx_gradQ(j, k, l, i, /*x*/0, m)] += 1.0 / dx[0] *
                      lQi[idx_lQi(j, k, n, i, m)] * kernels::dudx[order][l][n];
                }
              }
            }
          }
        }
      endpfor
      
      // y direction (independent from the x and z derivatives)
      //for (int j = 0; j < basisSize; j++) { // z
      pfor(j,0,basisSize,grainSizeComputeDerivatives.getGrainSize())
        for (int k = 0; k < basisSize; k++) { // x
          const double weight = kernels::gaussLegendreWeights[order][i] *
              kernels::gaussLegendreWeights[order][j] *
              kernels::gaussLegendreWeights[order][k];
          const double updateSize = weight * dt / dx[1];

          // Matrix operation
          for (int l = 0; l < basisSize; l++) { // y
            for (int m = 0; m < numberOfVariables; m++) {
              for (int n = 0; n < basisSize; n++) {
                rhs[idx_rhs(i, j, l, k, m)] -= updateSize *
                    lFi[idx_lFi(i, j, n, k, 1, m)] *
                    kernels::Kxi[order][n][l];
                if(useNCP) {
                  gradQ[idx_gradQ(j, l, k, i, /*y*/1, m)] += 1.0 / dx[1] *
                      lQi[idx_lQi(j, n, k, i, m)] * kernels::dudx[order][l][n];
                }
              }
            }
          }
        }
      endpfor
      
      // z direction (independent from the x and y derivatives)
      //for (int j = 0; j < basisSize; j++) { // y
      pfor(j,0,basisSize,grainSizeComputeDerivatives.getGrainSize())
        for (int k = 0; k < basisSize; k++) { // x 
          const double weight = kernels::gaussLegendreWeights[order][i] *
              kernels::gaussLegendreWeights[order][j] *
              kernels::gaussLegendreWeights[order][k];
          const double updateSize = weight * dt / dx[2];

          // Matrix operation
          for (int l = 0; l < basisSize; l++) { // z
            for (int m = 0; m < numberOfVariables; m++) {
              for (int n = 0; n < basisSize; n++) {
                rhs[idx_rhs(i, l, j, k, m)] -= updateSize *
                    lFi[idx_lFi(i, n, j, k, 2, m)] *
                    kernels::Kxi[order][n][l];
                if(useNCP) {
                  gradQ[idx_gradQ(l, j, k, i, /*z*/2, m)] += 1.0 / dx[2] *
                      lQi[idx_lQi(n, j, k, i, m)] * kernels::dudx[order][l][n];
                }
              }
            }
          }
        }
      endpfor
      
      if(useSource || useNCP) {
        // source
        auto grainSizeSourceNCP = peano::datatraversal::autotuning::Oracle::getInstance().parallelise(basisSize,sharedmemorylabels::GenericKernelsSourceNCP);
        //for (int j = 0; j < basisSize; j++) { // z
        pfor(j,0,basisSize,grainSizeSourceNCP.getGrainSize())
          for (int k = 0; k < basisSize; k++) { // y
            for (int l = 0; l < basisSize; l++) { // x
              const double weight = kernels::gaussLegendreWeights[order][i] *
                  kernels::gaussLegendreWeights[order][j] *
                  kernels::gaussLegendreWeights[order][k] *
                  kernels::gaussLegendreWeights[order][l];
              const double updateSize = weight * dt;
              double* S = lFi + idx_lFi(i, j, k, l, 3, 0);

              // by intention, gradQ is undefined here if useNCP is not true.
              // This is because algebraicSource is only a function of Q and S.
              solver.fusedSource(&lQi[idx_lQi(j, k, l, i, 0)], &gradQ[idx_gradQ(j, k, l, i, 0, 0)], S);

              for (int m = 0; m < numberOfVariables; m++) {
                rhs[idx_rhs(i, j, k, l, m)] += updateSize * S[m];
              }
            }
          }
        endpfor
        grainSizeSourceNCP.parallelSectionHasTerminated();
      }
    }  // end time dof

    // Zero out variables in lQi
    if (numberOfParameters==0) {
      std::memset(lQi, 0, basisSize4 * numberOfVariables * sizeof(double));
    } else {
      for (int i = 0; i < basisSize; i++) { // i == z
        for (int j = 0; j < basisSize; j++) { // j == y
          for (int k = 0; k < basisSize; k++) { // k == x
            for (int l = 0; l < basisSize; l++) { // l==t
              std::fill_n (lQi + idx_lQi(i, j, k, l, 0), numberOfVariables, 0.0);
            }
          }
        }
      }
    }
    
    // 4. Multiply with (K1)^(-1) to get the discrete time integral of the
    // discrete Picard iteration
    auto grainSizeDiscreteTimeIntegral = peano::datatraversal::autotuning::Oracle::getInstance().parallelise(basisSize,sharedmemorylabels::GenericKernelsDiscreteTimeIntegral);
    //for (int i = 0; i < basisSize; i++) {
    pfor(i,0,basisSize,grainSizeDiscreteTimeIntegral.getGrainSize())
      for (int j = 0; j < basisSize; j++) {
        for (int k = 0; k < basisSize; k++) {
          const double weight = kernels::gaussLegendreWeights[order][i] *
              kernels::gaussLegendreWeights[order][j] *
              kernels::gaussLegendreWeights[order][k];
          const double iweight = 1.0 / weight;

          // Matrix operation
          for (int l = 0; l < basisSize; l++) { // time
            for (int m = 0; m < numberOfVariables; m++) { 
              for (int n = 0; n < basisSize; n++) { // time
                lQi[idx_lQi(i, j, k, l, m)] += iweight *
                    rhs[idx_rhs(n, i, j, k, m)] *
                    kernels::iK1[order][l][n];
                // TODO: Check if we store iK1 or rather its transpose
              }
            }
          }
        }
      }
    endpfor
    grainSizeDiscreteTimeIntegral.parallelSectionHasTerminated();

    // 5. Exit condition
    constexpr double tol = 1e-7;
    double sq_res = 0.0;
    for (int i = 0; i < basisSize4 * numberOfData; i++) {
      sq_res += (lQi_old[i] - lQi[i]) * (lQi_old[i] - lQi[i]);
    }
    if (sq_res < tol * tol) {
      break;
    }

    if (iter == MaxIterations) {  // No convergence after last iteration
      static tarch::logging::Log _log("kernels::aderdg::generic::c");
      logWarning("aderPicardLoopNonlinear(...)",
          "|res|^2=" << sq_res << " > |tol|^2=" << tol * tol << " after "
          << iter << " iterations. Solver seems not to "
          "have converged properly within "
          "maximum number of iteration steps");
    }
  }  // end iter
}

/*
 *  Immediately compute the time - averaged space - time polynomials
 *  
 *  We have to consider that we store parameters in lQi
 *  and lQhi, and have to adjust the index accordingly.
 */
template <bool useSourceOrNCP, int numberOfVariables, int numberOfParameters, int basisSize>
void aderPredictorNonlinear(const double* lQi, const double* lFi,
    double* lQhi,double* lFhi_x, double* lFhi_y, double* lFhi_z,
    double* lShi) {
  // Immediately compute the time - averaged space - time polynomials

  constexpr int basisSize2 = basisSize * basisSize;
  constexpr int basisSize3 = basisSize2 * basisSize;
  constexpr int order = basisSize - 1;

  constexpr int numberOfData = numberOfVariables+numberOfParameters;

  idx5 idx_lQi(basisSize, basisSize, basisSize, basisSize, numberOfData);
  
  idx6 idx_lFi(basisSize, basisSize, basisSize, basisSize, DIMENSIONS + 1, numberOfVariables);

  idx4 idx_lQhi(basisSize, basisSize, basisSize, numberOfData);
  
  idx4 idx_lFhi(basisSize, basisSize, basisSize, numberOfVariables);
  idx4 idx_lShi(basisSize, basisSize, basisSize, numberOfVariables);

  std::fill_n(lQhi, basisSize3 * numberOfData, 0.0);
  
  std::fill_n(lFhi_x, basisSize3 * numberOfVariables, 0.0);
  std::fill_n(lFhi_y, basisSize3 * numberOfVariables, 0.0);
  std::fill_n(lFhi_z, basisSize3 * numberOfVariables, 0.0);
  std::fill_n(lShi,   basisSize3 * numberOfVariables, 0.0);

  for (int i = 0; i < basisSize; i++) {
    for (int j = 0; j < basisSize; j++) {
      for (int k = 0; k < basisSize; k++) {
        for (int l = 0; l < numberOfVariables; l++) {
          // Matrix-Vector Products
          for (int m = 0; m < basisSize; m++) {
            // Fortran: lFhi_x(:,k,j,i) = lFh(:,1,k,j,i,:) * wGPN(:)
            lFhi_x[idx_lFhi(i, j, k, l)] +=
                lFi[idx_lFi(m, i, j, k, 0, l)] *
                kernels::gaussLegendreWeights[order][m];

            // Fortran: lFhi_y(:,j,k,i) = lFh(:,2,:k,j,i,:) * wGPN(:)
            lFhi_y[idx_lFhi(i, k, j, l)] +=
                lFi[idx_lFi(m, i, j, k, 1, l)] *
                kernels::gaussLegendreWeights[order][m];

            // Fortran: lFhi_z(:,i,k,j) = lFh(:,3,k,j,i,:) * wGPN(:)
            lFhi_z[idx_lFhi(j, k, i, l)] +=
                lFi[idx_lFi(m, i, j, k, 2, l)] *
                kernels::gaussLegendreWeights[order][m];

            if(useSourceOrNCP) {
              // Fortran: lShi(:,k,j,i) = lSh(:,k,j,i,:) * wGPN(:)
              lShi[idx_lShi(i, j, k, l)] +=
                  lFi[idx_lFi(m, i, j, k, 3, l)] *
                  kernels::gaussLegendreWeights[order][m];
            }
            
          }
        }
        for (int l = 0; l < numberOfData; l++) {
          // Matrix-Vector Products
          for (int m = 0; m < basisSize; m++) {
            // Fortran: lQhi(:,k,j,i) = lQi(:,:,k,j,i) * wGPN(:)
            lQhi[idx_lQhi(i, j, k, l)] +=
                lQi[idx_lQi(i, j, k, m, l)] *
                kernels::gaussLegendreWeights[order][m];
          }
        }
      }
    }
  }
}

template <int numberOfVariables, int numberOfParameters, int basisSize>
void aderExtrapolatorNonlinear(const double* lQhi, const double* lFhi_x,
    const double* lFhi_y, const double* lFhi_z, double* lQhbnd, double* lFhbnd) {
  // Compute the boundary-extrapolated values for Q and F*n
  constexpr int basisSize2 = basisSize * basisSize;
  constexpr int order = basisSize - 1;

  constexpr int numberOfData = numberOfVariables+numberOfParameters;

  idx4 idx_lQhi(basisSize, basisSize, basisSize, numberOfData);
  
  idx4 idx_lFhi(basisSize, basisSize, basisSize, numberOfVariables);

  
  idx4 idx_lQhbnd(2 * DIMENSIONS, basisSize, basisSize, numberOfData);
  
  idx4 idx_lFhbnd(2 * DIMENSIONS, basisSize, basisSize, numberOfVariables);

  std::fill_n(lQhbnd, 2 * DIMENSIONS * basisSize2 *  numberOfData, 0.0);
  std::fill_n(lFhbnd, 2 * DIMENSIONS * basisSize2 * numberOfVariables, 0.0);

  // x-direction: face 1 (left) and face 2 (right)
  for (int i = 0; i < basisSize; i++) {
    for (int j = 0; j < basisSize; j++) {
      // Matrix-Vector Products
      for (int k = 0; k < numberOfVariables; k++) {
        for (int l = 0; l < basisSize; l++) {
          // Fortran: lFhbnd(:,j,i,1) = lFhi_x(:,:,j,i) * FLCoeff(:)
          lFhbnd[idx_lFhbnd(0, i, j, k)] +=
              lFhi_x[idx_lFhi(i, j, l, k)] * kernels::FLCoeff[order][l];

          // Fortran: lFhbnd(:,j,i,2) = lFhi_x(:,:,j,i) * FRCoeff(:)
          lFhbnd[idx_lFhbnd(1, i, j, k)] +=
              lFhi_x[idx_lFhi(i, j, l, k)] * kernels::FRCoeff[order][l];
        }
      }
      for (int k = 0; k < numberOfData; k++) {
        for (int l = 0; l < basisSize; l++) {
          // Fortran: lQhbnd(:,j,i,1) = lQhi(:,:,j,i) * FLCoeff(:)
          lQhbnd[idx_lQhbnd(0, i, j, k)] +=
              lQhi[idx_lQhi(i, j, l, k)] * kernels::FLCoeff[order][l];

          // Fortran: lQhbnd(:,j,i,2) = lQhi(:,:,j,i) * FRCoeff(:)
          lQhbnd[idx_lQhbnd(1, i, j, k)] +=
              lQhi[idx_lQhi(i, j, l, k)] * kernels::FRCoeff[order][l];
        }
      }
    }
  }

  // y-direction: face 3 (left) and face 4 (right)
  for (int i = 0; i < basisSize; i++) {
    for (int j = 0; j < basisSize; j++) {
      for (int k = 0; k < numberOfVariables; k++) {
        // Matrix-Vector Products
        for (int l = 0; l < basisSize; l++) {
          // Fortran: lFhbnd(:,j,i,3) = lFhi_y(:,:,j,i) * FLCoeff(:)
          lFhbnd[idx_lFhbnd(2, i, j, k)] +=
              lFhi_y[idx_lFhi(i, j, l, k)] * kernels::FLCoeff[order][l];

          // Fortran: lFhbnd(:,j,i,4) = lFhi_y(:,:,j,i) * FRCoeff(:)
          lFhbnd[idx_lFhbnd(3, i, j, k)] +=
              lFhi_y[idx_lFhi(i, j, l, k)] * kernels::FRCoeff[order][l];
        }
      }
      for (int k = 0; k < numberOfData; k++) {
        // Matrix-Vector Products
        for (int l = 0; l < basisSize; l++) {
          // Fortran: lQhbnd(:,j,i,3) = lQhi(:,j,:,i) * FLCoeff(:)
          lQhbnd[idx_lQhbnd(2, i, j, k)] +=
              lQhi[idx_lQhi(i, l, j, k)] * kernels::FLCoeff[order][l];

          // Fortran: lQhbnd(:,j,i,4) = lQhi(:,j,:,i) * FRCoeff(:)
          lQhbnd[idx_lQhbnd(3, i, j, k)] +=
              lQhi[idx_lQhi(i, l, j, k)] * kernels::FRCoeff[order][l];
        }
      }
    }
  }

  // z-direction: face 5 (left) and face 6 (right)
  for (int i = 0; i < basisSize; i++) {
    for (int j = 0; j < basisSize; j++) {
      for (int k = 0; k < numberOfVariables; k++) {
        // Matrix-Vector Products
        for (int l = 0; l < basisSize; l++) {
          // Fortran: lFhbnd(:,j,i,5) = lFhi_z(:,:,j,i) * FLCoeff(:)
          lFhbnd[idx_lFhbnd(4, i, j, k)] +=
              lFhi_z[idx_lFhi(i, j, l, k)] * kernels::FLCoeff[order][l];

          // Fortran: lFhbnd(:,j,i,6) = lFhi_z(:,:,j,i) * FRCoeff(:)
          lFhbnd[idx_lFhbnd(5, i, j, k)] +=
              lFhi_z[idx_lFhi(i, j, l, k)] * kernels::FRCoeff[order][l];
        }
      }
      for (int k = 0; k < numberOfData; k++) {
        // Matrix-Vector Products
        for (int l = 0; l < basisSize; l++) {
          // Fortran: lQhbnd(:,j,i,5) = lQhi(:,j,i,:) * FLCoeff(:)
          lQhbnd[idx_lQhbnd(4, i, j, k)] +=
              lQhi[idx_lQhi(l, i, j, k)] * kernels::FLCoeff[order][l];

          // Fortran: lQhbnd(:,j,i,6) = lQhi(:,j,i,:) * FRCoeff(:)
          lQhbnd[idx_lQhbnd(5, i, j, k)] +=
              lQhi[idx_lQhi(l, i, j, k)] * kernels::FRCoeff[order][l];
        }
      }
    }
  }
}

}  // namespace

template <typename SolverType>
void spaceTimePredictorNonlinear(
    SolverType& solver,
    double*  lQhbnd, double* lFhbnd,
    double** tempSpaceTimeUnknowns,
    double** tempSpaceTimeFluxUnknowns,
    double*  tempUnknowns,
    double*  tempFluxUnknowns,
    double*  tempStateSizedVector,
    const double* const luh,
    const tarch::la::Vector<DIMENSIONS, double>& dx, 
    double dt
) {
  constexpr int numberOfVariables  = SolverType::NumberOfVariables;
  constexpr int numberOfParameters = SolverType::NumberOfParameters;
  constexpr int basisSize          = SolverType::Order+1;
  constexpr int basisSize2         = basisSize * basisSize;
  constexpr int basisSize3         = basisSize2 * basisSize;

  const bool useSource = solver.useAlgebraicSource();
  const bool useNCP    = solver.useNonConservativeProduct();

  double* lQi     = tempSpaceTimeUnknowns[0];
  double* lQi_old = tempSpaceTimeUnknowns[1];
  double* rhs     = tempSpaceTimeUnknowns[2];
  double* rhs_0   = tempSpaceTimeUnknowns[3];

  double* lFi     = tempSpaceTimeFluxUnknowns[0];
  double* gradQ   = tempSpaceTimeFluxUnknowns[1]; // size: basisSize3 * DIMENSIONS * numberOfVariables

  double *lQhi    = tempUnknowns;

  double *lFhi    = tempFluxUnknowns;

  double *BGradQ  = tempStateSizedVector; // size: numberOfVariables

  if(useSource) {
    if(useNCP) {
      aderPicardLoopNonlinear<true, true, SolverType>(solver, luh, dt, dx,
        lQi, lQi_old, rhs, rhs_0, lFi, gradQ, BGradQ);
    } else {
      aderPicardLoopNonlinear<true, false, SolverType>(solver, luh, dt, dx,
        lQi, lQi_old, rhs, rhs_0, lFi, gradQ, BGradQ);
    }
  } else {
    if(useNCP) {
      aderPicardLoopNonlinear<false, true, SolverType>(solver, luh, dt, dx,
        lQi, lQi_old, rhs, rhs_0, lFi, gradQ, BGradQ);
    } else {
      aderPicardLoopNonlinear<false, false, SolverType>(solver, luh, dt, dx,
        lQi, lQi_old, rhs, rhs_0, lFi, gradQ, BGradQ);
    }
  }

  if(useSource || useNCP) {
    aderPredictorNonlinear<true, numberOfVariables, numberOfParameters, basisSize>(lQi, lFi, lQhi,
        &lFhi[0 * basisSize3 * numberOfVariables],  // lFhi_x
        &lFhi[1 * basisSize3 * numberOfVariables],  // lFhi_y
        &lFhi[2 * basisSize3 * numberOfVariables],  // lFhi_z
        &lFhi[3 * basisSize3 * numberOfVariables]   // lShi
    );
  } else {
    aderPredictorNonlinear<false, numberOfVariables, numberOfParameters, basisSize>(lQi, lFi, lQhi,
        &lFhi[0 * basisSize3 * numberOfVariables],  // lFhi_x
        &lFhi[1 * basisSize3 * numberOfVariables],  // lFhi_y
        &lFhi[2 * basisSize3 * numberOfVariables],  // lFhi_z
        &lFhi[3 * basisSize3 * numberOfVariables]   // lShi
    );
  }

  aderExtrapolatorNonlinear<numberOfVariables, numberOfParameters, basisSize>(
      lQhi,
      &lFhi[0 * basisSize3 * numberOfVariables],  // lFhi_x
      &lFhi[1 * basisSize3 * numberOfVariables],  // lFhi_y
      &lFhi[2 * basisSize3 * numberOfVariables],  // lFhi_z
      lQhbnd, lFhbnd);
}

}  // namespace c
}  // namespace generic
}  // namespace aderdg
}  // namespace kernels

#endif  // DIMENSIONS == 3
